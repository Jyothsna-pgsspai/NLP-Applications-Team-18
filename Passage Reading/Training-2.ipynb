{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training-2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMm4Wy4Jzr+Dd2Zsb24nE8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7zfohx-K-zjT","colab_type":"code","outputId":"56731449-191c-4f9e-b51d-41ea0a7f7d8d","executionInfo":{"status":"ok","timestamp":1587220784132,"user_tz":-330,"elapsed":43123,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c5DowPil--2q","colab_type":"code","outputId":"780fc9af-90b8-49f4-f804-e22190656331","executionInfo":{"status":"ok","timestamp":1587220789991,"user_tz":-330,"elapsed":4641,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd \"/content/gdrive/My Drive/Project/drqa/scripts\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Project/drqa/scripts\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"32gZQfQ__WHv","colab_type":"code","outputId":"8ad103a4-8086-4571-dd63-6c07b0fd9e0e","executionInfo":{"status":"ok","timestamp":1587220794403,"user_tz":-330,"elapsed":6868,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["convert       drqa\t    models\t     Untitled1.ipynb\n","data.msgpack  meta.msgpack  Untitled0.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Peis-NQy_XvH","colab_type":"code","colab":{}},"source":["import re\n","import os\n","import sys\n","import math\n","import random\n","import string\n","import logging\n","import argparse\n","from shutil import copyfile\n","from datetime import datetime\n","from collections import Counter\n","import torch\n","import msgpack\n","from drqa.model import DocReaderModel\n","from drqa.utils import str2bool"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLI5rQRDFQSw","colab_type":"code","outputId":"9b95ac7e-1a6c-4e27-adf9-fd1408c69e85","executionInfo":{"status":"ok","timestamp":1587220807202,"user_tz":-330,"elapsed":2750,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(torch.cuda.is_available())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hlk_LHMA_o8k","colab_type":"code","colab":{}},"source":["#Creating a class of arguments\n","class arguments:\n","  def __init__(self):\n","  #System\n","    self.log_per_updates=3 #log model loss per x updates (mini-batches).\n","    self.data_file='data.msgpack' #data messagepack from preprocessing data\n","    self.model_dir='models' #folder name where models have to be loaded\n","    self.save_last_only=True #Only save the final models\n","    self.save_dawn_logs=True #append dawnbench log entries prefixed with dawn_entry:\n","    self.seed=1013 #random seed for data shuffling, dropout, etc.\n","    self.cuda=True #GPU usage\n","\n","  #Training\n","    self.epochs=40 #Number of epochs\n","    self.batch_size=32 #Batch size\n","    self.resume='best_model.pt' #Best model name if already present\n","    self.resume_options=True #use previous model options, ignore the cli and defaults\n","    self.reduce_lr=0 #reduce initial (resumed) learning rate by this factor\n","    self.optimizer='adamax' #supported optimizer: adamax, sgd\n","    self.grad_clipping=10 \n","    self.weight_decay=0\n","    self.learning_rate=0.1 #only applied to SGD\n","    self.momentum=0 #only applied to SGD\n","    self.tune_partial=0 #finetune top-x embeddings\n","    self.fix_embeddings=True #if true, `tune_partial` will be ignored\n","    self.rnn_padding=True #perform rnn padding (much slower but more accurate)\n","\n","  #model\n","    self.question_merge='self_attn'\n","    self.doc_layers=3\n","    self.question_layers=3\n","    self.hidden_size=128\n","    self.num_features=4\n","    self.pos=True #use pos tags as a feature\n","    self.ner=True #use named entity tags as a feature\n","    self.use_qemb=True \n","    self.concat_rnn_layers=True\n","    self.dropout_emb=0.4\n","    self.dropout_rnn=0.4\n","    self.dropout_rnn_output=True\n","    self.max_len=15\n","    self.rnn_type='lstm' #supported types: rnn, gru, lstm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ro3hmkMGa0W","colab_type":"code","colab":{}},"source":["args=arguments()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYyEXYrvGcT8","colab_type":"code","colab":{}},"source":["# set model dir\n","model_dir = args.model_dir\n","os.makedirs(model_dir, exist_ok=True)\n","args.model_dir = os.path.abspath(model_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Opavha-ZpP34","colab_type":"text"},"source":["If model is already there we'll use that model for restarting our training"]},{"cell_type":"code","metadata":{"id":"fThPE72tGlMp","colab_type":"code","colab":{}},"source":["if args.resume == 'best_model.pt' and not os.path.exists(os.path.join(args.model_dir, args.resume)):\n","        # means we're starting fresh\n","        args.resume = ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcDy6uHUvfnS","colab_type":"code","outputId":"729ef967-ca74-4f14-fca6-5a9abd5a663e","executionInfo":{"status":"ok","timestamp":1587220979249,"user_tz":-330,"elapsed":1867,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(args.resume)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["best_model.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uhUJFQljGwG-","colab_type":"code","colab":{}},"source":["# set random seed\n","random.seed(args.seed)\n","torch.manual_seed(args.seed)\n","if args.cuda:\n","    torch.cuda.manual_seed(args.seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7KSSj74G4Ip","colab_type":"code","colab":{}},"source":["# setup logger\n","class ProgressHandler(logging.Handler):\n","        def __init__(self, level=logging.NOTSET):\n","            super().__init__(level)\n","\n","        def emit(self, record):\n","            log_entry = self.format(record)\n","            if record.message.startswith('> '):\n","                sys.stdout.write('{}\\r'.format(log_entry.rstrip()))\n","                sys.stdout.flush()\n","            else:\n","                sys.stdout.write('{}\\n'.format(log_entry))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwNNmMsOG9tq","colab_type":"code","colab":{}},"source":["log = logging.getLogger(__name__)\n","log.setLevel(logging.DEBUG)\n","fh = logging.FileHandler(os.path.join(args.model_dir, 'log.txt'))\n","fh.setLevel(logging.INFO)\n","ch = ProgressHandler()\n","ch.setLevel(logging.DEBUG)\n","formatter = logging.Formatter(fmt='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S')\n","fh.setFormatter(formatter)\n","ch.setFormatter(formatter)\n","log.addHandler(fh)\n","log.addHandler(ch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHJuBrVaIWGo","colab_type":"code","colab":{}},"source":["def lr_decay(optimizer, lr_decay):\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] *= lr_decay\n","    return optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNfbHOUzLJVr","colab_type":"code","colab":{}},"source":["class BatchGen:\n","    pos_size = None\n","    ner_size = None\n","\n","    def __init__(self, data, batch_size, gpu, evaluation=False):\n","        \"\"\"\n","        input:\n","            data - list of lists\n","            batch_size - int\n","        \"\"\"\n","        self.batch_size = batch_size\n","        self.eval = evaluation\n","        self.gpu = gpu\n","\n","        # sort by len\n","        data = sorted(data, key=lambda x: len(x[1]))\n","        # chunk into batches\n","        data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n","\n","        # shuffle\n","        if not evaluation:\n","            random.shuffle(data)\n","\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __iter__(self):\n","        for batch in self.data:\n","            batch_size = len(batch)\n","            batch = list(zip(*batch))\n","            if self.eval:\n","                assert len(batch) == 8\n","            else:\n","                assert len(batch) == 10\n","\n","            context_len = max(len(x) for x in batch[1])\n","            context_id = torch.LongTensor(batch_size, context_len).fill_(0)\n","            for i, doc in enumerate(batch[1]):\n","                context_id[i, :len(doc)] = torch.LongTensor(doc)\n","\n","            feature_len = len(batch[2][0][0])\n","\n","            context_feature = torch.Tensor(batch_size, context_len, feature_len).fill_(0)\n","            for i, doc in enumerate(batch[2]):\n","                for j, feature in enumerate(doc):\n","                    context_feature[i, j, :] = torch.Tensor(feature)\n","\n","            context_tag = torch.Tensor(batch_size, context_len, self.pos_size).fill_(0)\n","            for i, doc in enumerate(batch[3]):\n","                for j, tag in enumerate(doc):\n","                    context_tag[i, j, tag] = 1\n","\n","            context_ent = torch.Tensor(batch_size, context_len, self.ner_size).fill_(0)\n","            for i, doc in enumerate(batch[4]):\n","                for j, ent in enumerate(doc):\n","                    context_ent[i, j, ent] = 1\n","\n","            question_len = max(len(x) for x in batch[5])\n","            question_id = torch.LongTensor(batch_size, question_len).fill_(0)\n","            for i, doc in enumerate(batch[5]):\n","                question_id[i, :len(doc)] = torch.LongTensor(doc)\n","\n","            context_mask = torch.eq(context_id, 0)\n","            question_mask = torch.eq(question_id, 0)\n","            text = list(batch[6])\n","            span = list(batch[7])\n","            if not self.eval:\n","                y_s = torch.LongTensor(batch[8])\n","                y_e = torch.LongTensor(batch[9])\n","            if self.gpu:\n","                context_id = context_id.pin_memory()\n","                context_feature = context_feature.pin_memory()\n","                context_tag = context_tag.pin_memory()\n","                context_ent = context_ent.pin_memory()\n","                context_mask = context_mask.pin_memory()\n","                question_id = question_id.pin_memory()\n","                question_mask = question_mask.pin_memory()\n","            if self.eval:\n","                yield (context_id, context_feature, context_tag, context_ent, context_mask,\n","                       question_id, question_mask, text, span)\n","            else:\n","                yield (context_id, context_feature, context_tag, context_ent, context_mask,\n","                       question_id, question_mask, y_s, y_e, text, span)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrqQmReJIYEu","colab_type":"code","colab":{}},"source":["def load_data(opt):\n","    with open('meta.msgpack', 'rb') as f:\n","        meta = msgpack.load(f)\n","    embedding = torch.Tensor(meta['embedding'])\n","    opt['pretrained_words'] = True\n","    opt['vocab_size'] = embedding.size(0) #Embedding rows length which is vocab length\n","    opt['embedding_dim'] = embedding.size(1) #Embedding columns which is word vector dimesions \n","    opt['pos_size'] = len(meta['vocab_tag']) #Vocab POS tags length\n","    opt['ner_size'] = len(meta['vocab_ent']) #Vocab NER tags length\n","    BatchGen.pos_size = opt['pos_size'] #We are assigning the Batch size pos size with number of pos tags\n","    BatchGen.ner_size = opt['ner_size'] #We are assigning the Batch size NER size with number of NER tags\n","    with open(opt['data_file'], 'rb') as f:\n","        data = msgpack.load(f)\n","    train = data['train'] #Assinging complete train data \n","    data['dev'].sort(key=lambda x: len(x[1]))\n","    dev = [x[:-1] for x in data['dev']] #Assigning all id, context_id, context_features, tag_id, ent_id, question_id, context, context_token_span\n","    dev_y = [x[-1] for x in data['dev']] #Assigning answers to the dev_y\n","    return train, dev, dev_y, embedding, opt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WelpLt_Ise5","colab_type":"code","colab":{}},"source":["train, dev, dev_y, embedding, opt = load_data(vars(args))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AngXhHSwIv-y","colab_type":"code","outputId":"31838e94-f4b7-498b-b03b-97ec99acfde3","executionInfo":{"status":"ok","timestamp":1587220886834,"user_tz":-330,"elapsed":43706,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["log.info(opt)\n","log.info('[Data loaded.]')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["04/18/2020 02:41:22 {'log_per_updates': 3, 'data_file': 'data.msgpack', 'model_dir': '/content/gdrive/My Drive/Project/drqa/scripts/models', 'save_last_only': True, 'save_dawn_logs': True, 'seed': 1013, 'cuda': True, 'epochs': 40, 'batch_size': 32, 'resume': 'best_model.pt', 'resume_options': True, 'reduce_lr': 0, 'optimizer': 'adamax', 'grad_clipping': 10, 'weight_decay': 0, 'learning_rate': 0.1, 'momentum': 0, 'tune_partial': 0, 'fix_embeddings': True, 'rnn_padding': True, 'question_merge': 'self_attn', 'doc_layers': 3, 'question_layers': 3, 'hidden_size': 128, 'num_features': 4, 'pos': True, 'ner': True, 'use_qemb': True, 'concat_rnn_layers': True, 'dropout_emb': 0.4, 'dropout_rnn': 0.4, 'dropout_rnn_output': True, 'max_len': 15, 'rnn_type': 'lstm', 'pretrained_words': True, 'vocab_size': 91590, 'embedding_dim': 300, 'pos_size': 50, 'ner_size': 19}\n","04/18/2020 02:41:24 [Data loaded.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ql3f3G7UNRVu","colab_type":"code","outputId":"31a3777a-91f6-4ce6-ddec-1223faacffe6","executionInfo":{"status":"ok","timestamp":1587220886836,"user_tz":-330,"elapsed":39372,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if args.save_dawn_logs:\n","        dawn_start = datetime.now()\n","        log.info('dawn_entry: epoch\\tf1Score\\thours')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["04/18/2020 02:41:24 dawn_entry: epoch\tf1Score\thours\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hXp5JkuFN9-Y","colab_type":"code","colab":{}},"source":["if args.resume:\n","        log.info('[loading previous model...]')\n","        checkpoint = torch.load(os.path.join(args.model_dir, args.resume))\n","        if args.resume_options:\n","            opt = checkpoint['config']\n","        state_dict = checkpoint['state_dict']\n","        model = DocReaderModel(opt, embedding, state_dict)\n","        epoch_0 = checkpoint['epoch'] + 1\n","        # synchronize random seed\n","        random.setstate(checkpoint['random_state'])\n","        torch.random.set_rng_state(checkpoint['torch_state'])\n","        if args.cuda:\n","            torch.cuda.set_rng_state(checkpoint['torch_cuda_state'])\n","        if args.reduce_lr:\n","            lr_decay(model.optimizer, lr_decay=args.reduce_lr)\n","            log.info('[learning rate reduced by {}]'.format(args.reduce_lr))\n","        batches = BatchGen(dev, batch_size=args.batch_size, evaluation=True, gpu=args.cuda)\n","        predictions = []\n","        for i, batch in enumerate(batches):\n","            predictions.extend(model.predict(batch))\n","            log.debug('> evaluating [{}/{}]'.format(i, len(batches)))\n","        em, f1 = score(predictions, dev_y)\n","        log.info(\"[dev EM: {} F1: {}]\".format(em, f1))\n","        if math.fabs(em - checkpoint['em']) > 1e-3 or math.fabs(f1 - checkpoint['f1']) > 1e-3:\n","            log.info('Inconsistent: recorded EM: {} F1: {}'.format(checkpoint['em'], checkpoint['f1']))\n","            log.error('Error loading model: current code is inconsistent with code used to train the previous model.')\n","            exit(1)\n","        best_val_score = checkpoint['best_eval']\n","else:  \n","        model = DocReaderModel(opt, embedding)\n","        epoch_0 = 1\n","        best_val_score = 0.0\n","\n","#Calls Doc Reader Model that handles the intializing, underlying network architecture, saving, updating ad predicting examples.\n","#First it calls AverageMeter() -->beta=0.99, moment=0, value=0, t=0\n","#It assigns RnnDocReader network to network variable\n","#In RnnDocReader we are using lstm. \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ORsnGbzXoz1","colab_type":"code","colab":{}},"source":["def _normalize_answer(s):\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def _exact_match(pred, answers):\n","    if pred is None or answers is None:\n","        return False\n","    pred = _normalize_answer(pred)\n","    for a in answers:\n","        if pred == _normalize_answer(a):\n","            return True\n","    return False\n","\n","\n","def _f1_score(pred, answers):\n","    def _score(g_tokens, a_tokens):\n","        common = Counter(g_tokens) & Counter(a_tokens)\n","        num_same = sum(common.values())\n","        if num_same == 0:\n","            return 0\n","        precision = 1. * num_same / len(g_tokens)\n","        recall = 1. * num_same / len(a_tokens)\n","        f1 = (2 * precision * recall) / (precision + recall)\n","        return f1\n","\n","    if pred is None or answers is None:\n","        return 0\n","    g_tokens = _normalize_answer(pred).split()\n","    scores = [_score(g_tokens, _normalize_answer(a).split()) for a in answers]\n","    return max(scores)\n","\n","\n","def score(pred, truth):\n","    assert len(pred) == len(truth)\n","    f1 = em = total = 0\n","    for p, t in zip(pred, truth):\n","        total += 1\n","        em += _exact_match(p, t)\n","        f1 += _f1_score(p, t)\n","    em = 100. * em / total\n","    f1 = 100. * f1 / total\n","    return em, f1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cwd7bJWVbEb1","colab_type":"code","outputId":"5d3dc689-69fd-4a4f-b293-0086b28945bf","executionInfo":{"status":"ok","timestamp":1587220656664,"user_tz":-330,"elapsed":30228,"user":{"displayName":"Jyothsna Munipalle","photoUrl":"","userId":"01874070639261093213"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[" for epoch in range(epoch_0, epoch_0 + args.epochs):\n","        log.warning('Epoch {}'.format(epoch))\n","        # train\n","        batches = BatchGen(train, batch_size=args.batch_size, gpu=args.cuda)\n","        start = datetime.now()\n","        for i, batch in enumerate(batches):\n","            model.update(batch) #Here we are updatign model with train data batch\n","            if i % args.log_per_updates == 0:\n","                log.info('> epoch [{0:2}] updates[{1:6}] train loss[{2:.5f}] remaining[{3}]'.format(\n","                    epoch, model.updates, model.train_loss.value,\n","                    str((datetime.now() - start) / (i + 1) * (len(batches) - i - 1)).split('.')[0]))\n","        log.debug('\\n')\n","        # evaluation=True there is no shuffing of data during batch generation\n","        batches = BatchGen(dev, batch_size=args.batch_size, evaluation=True, gpu=args.cuda)\n","        predictions = []\n","        for i, batch in enumerate(batches):\n","            predictions.extend(model.predict(batch)) #Here we are predicting the answers for dev st using dev batch gneration\n","            log.debug('> evaluating [{}/{}]'.format(i, len(batches)))\n","        em, f1 = score(predictions, dev_y)\n","        log.warning(\"dev EM: {} F1: {}\".format(em, f1))\n","        if args.save_dawn_logs:\n","            time_diff = datetime.now() - dawn_start\n","            log.warning(\"dawn_entry: {}\\t{}\\t{}\".format(epoch, f1/100.0, float(time_diff.total_seconds() / 3600.0)))\n","        # save\n","        if not args.save_last_only or epoch == epoch_0 + args.epochs - 1:\n","            model_file = os.path.join(args.model_dir, 'checkpoint_epoch_{}.pt'.format(epoch))\n","            model.save(model_file, epoch, [em, f1, best_val_score])\n","            if f1 > best_val_score:\n","                best_val_score = f1\n","                copyfile(\n","                    model_file,\n","                    os.path.join(args.model_dir, 'best_model.pt'))\n","                log.info('[new best model saved.]')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["04/18/2020 08:34:54 Epoch 1\n","04/18/2020 08:34:54 Epoch 1\n","04/18/2020 08:34:54 Epoch 1\n","04/18/2020 08:42:49 \n","\n","04/18/2020 08:42:49 \n","\n","04/18/2020 08:42:49 \n","\n","04/18/2020 08:43:40 dev EM: 53.4720908230842 F1: 64.43750696880365\n","04/18/2020 08:43:40 dev EM: 53.4720908230842 F1: 64.43750696880365\n","04/18/2020 08:43:40 dev EM: 53.4720908230842 F1: 64.43750696880365\n","04/18/2020 08:43:40 dawn_entry: 1\t0.6443750696880365\t0.2294558113888889\n","04/18/2020 08:43:40 dawn_entry: 1\t0.6443750696880365\t0.2294558113888889\n","04/18/2020 08:43:40 dawn_entry: 1\t0.6443750696880365\t0.2294558113888889\n","04/18/2020 08:43:40 Epoch 2\n","04/18/2020 08:43:40 Epoch 2\n","04/18/2020 08:43:40 Epoch 2\n","04/18/2020 08:51:37 \n","\n","04/18/2020 08:51:37 \n","\n","04/18/2020 08:51:37 \n","\n","04/18/2020 08:52:28 dev EM: 58.7038789025544 F1: 69.0823891660754\n","04/18/2020 08:52:28 dev EM: 58.7038789025544 F1: 69.0823891660754\n","04/18/2020 08:52:28 dev EM: 58.7038789025544 F1: 69.0823891660754\n","04/18/2020 08:52:28 dawn_entry: 2\t0.690823891660754\t0.3760885711111111\n","04/18/2020 08:52:28 dawn_entry: 2\t0.690823891660754\t0.3760885711111111\n","04/18/2020 08:52:28 dawn_entry: 2\t0.690823891660754\t0.3760885711111111\n","04/18/2020 08:52:28 Epoch 3\n","04/18/2020 08:52:28 Epoch 3\n","04/18/2020 08:52:28 Epoch 3\n","04/18/2020 09:00:25 \n","\n","04/18/2020 09:00:25 \n","\n","04/18/2020 09:00:25 \n","\n","04/18/2020 09:01:16 dev EM: 60.78524124881741 F1: 71.49297772340229\n","04/18/2020 09:01:16 dev EM: 60.78524124881741 F1: 71.49297772340229\n","04/18/2020 09:01:16 dev EM: 60.78524124881741 F1: 71.49297772340229\n","04/18/2020 09:01:16 dawn_entry: 3\t0.714929777234023\t0.5227847944444444\n","04/18/2020 09:01:16 dawn_entry: 3\t0.714929777234023\t0.5227847944444444\n","04/18/2020 09:01:16 dawn_entry: 3\t0.714929777234023\t0.5227847944444444\n","04/18/2020 09:01:16 Epoch 4\n","04/18/2020 09:01:16 Epoch 4\n","04/18/2020 09:01:16 Epoch 4\n","04/18/2020 09:09:16 \n","\n","04/18/2020 09:09:16 \n","\n","04/18/2020 09:09:16 \n","\n","04/18/2020 09:10:06 dev EM: 62.19489120151372 F1: 72.70108232934315\n","04/18/2020 09:10:06 dev EM: 62.19489120151372 F1: 72.70108232934315\n","04/18/2020 09:10:06 dev EM: 62.19489120151372 F1: 72.70108232934315\n","04/18/2020 09:10:06 dawn_entry: 4\t0.7270108232934315\t0.67012753\n","04/18/2020 09:10:06 dawn_entry: 4\t0.7270108232934315\t0.67012753\n","04/18/2020 09:10:06 dawn_entry: 4\t0.7270108232934315\t0.67012753\n","04/18/2020 09:10:06 Epoch 5\n","04/18/2020 09:10:06 Epoch 5\n","04/18/2020 09:10:06 Epoch 5\n","04/18/2020 09:18:04 \n","\n","04/18/2020 09:18:04 \n","\n","04/18/2020 09:18:04 \n","\n","04/18/2020 09:18:54 dev EM: 63.92620624408704 F1: 73.6455915114281\n","04/18/2020 09:18:54 dev EM: 63.92620624408704 F1: 73.6455915114281\n","04/18/2020 09:18:54 dev EM: 63.92620624408704 F1: 73.6455915114281\n","04/18/2020 09:18:54 dawn_entry: 5\t0.736455915114281\t0.8167294763888888\n","04/18/2020 09:18:54 dawn_entry: 5\t0.736455915114281\t0.8167294763888888\n","04/18/2020 09:18:54 dawn_entry: 5\t0.736455915114281\t0.8167294763888888\n","04/18/2020 09:18:54 Epoch 6\n","04/18/2020 09:18:54 Epoch 6\n","04/18/2020 09:18:54 Epoch 6\n","04/18/2020 09:26:51 \n","\n","04/18/2020 09:26:51 \n","\n","04/18/2020 09:26:51 \n","\n","04/18/2020 09:27:41 dev EM: 64.95742667928099 F1: 74.76885281372009\n","04/18/2020 09:27:41 dev EM: 64.95742667928099 F1: 74.76885281372009\n","04/18/2020 09:27:41 dev EM: 64.95742667928099 F1: 74.76885281372009\n","04/18/2020 09:27:41 dawn_entry: 6\t0.7476885281372009\t0.9632069772222223\n","04/18/2020 09:27:41 dawn_entry: 6\t0.7476885281372009\t0.9632069772222223\n","04/18/2020 09:27:41 dawn_entry: 6\t0.7476885281372009\t0.9632069772222223\n","04/18/2020 09:27:41 Epoch 7\n","04/18/2020 09:27:41 Epoch 7\n","04/18/2020 09:27:41 Epoch 7\n","04/18/2020 09:35:48 \n","\n","04/18/2020 09:35:48 \n","\n","04/18/2020 09:35:48 \n","\n","04/18/2020 09:36:40 dev EM: 65.69536423841059 F1: 75.27339570519254\n","04/18/2020 09:36:40 dev EM: 65.69536423841059 F1: 75.27339570519254\n","04/18/2020 09:36:40 dev EM: 65.69536423841059 F1: 75.27339570519254\n","04/18/2020 09:36:40 dawn_entry: 7\t0.7527339570519254\t1.1128827630555556\n","04/18/2020 09:36:40 dawn_entry: 7\t0.7527339570519254\t1.1128827630555556\n","04/18/2020 09:36:40 dawn_entry: 7\t0.7527339570519254\t1.1128827630555556\n","04/18/2020 09:36:40 Epoch 8\n","04/18/2020 09:36:40 Epoch 8\n","04/18/2020 09:36:40 Epoch 8\n","04/18/2020 09:44:45 \n","\n","04/18/2020 09:44:45 \n","\n","04/18/2020 09:44:45 \n","\n","04/18/2020 09:45:38 dev EM: 65.68590350047303 F1: 75.6907804005291\n","04/18/2020 09:45:38 dev EM: 65.68590350047303 F1: 75.6907804005291\n","04/18/2020 09:45:38 dev EM: 65.68590350047303 F1: 75.6907804005291\n","04/18/2020 09:45:38 dawn_entry: 8\t0.7569078040052911\t1.2622495841666668\n","04/18/2020 09:45:38 dawn_entry: 8\t0.7569078040052911\t1.2622495841666668\n","04/18/2020 09:45:38 dawn_entry: 8\t0.7569078040052911\t1.2622495841666668\n","04/18/2020 09:45:38 Epoch 9\n","04/18/2020 09:45:38 Epoch 9\n","04/18/2020 09:45:38 Epoch 9\n","04/18/2020 09:53:41 \n","\n","04/18/2020 09:53:41 \n","\n","04/18/2020 09:53:41 \n","\n","04/18/2020 09:54:33 dev EM: 66.05487228003784 F1: 76.2520339223346\n","04/18/2020 09:54:33 dev EM: 66.05487228003784 F1: 76.2520339223346\n","04/18/2020 09:54:33 dev EM: 66.05487228003784 F1: 76.2520339223346\n","04/18/2020 09:54:33 dawn_entry: 9\t0.762520339223346\t1.4107807252777778\n","04/18/2020 09:54:33 dawn_entry: 9\t0.762520339223346\t1.4107807252777778\n","04/18/2020 09:54:33 dawn_entry: 9\t0.762520339223346\t1.4107807252777778\n","04/18/2020 09:54:33 Epoch 10\n","04/18/2020 09:54:33 Epoch 10\n","04/18/2020 09:54:33 Epoch 10\n","04/18/2020 10:02:37 \n","\n","04/18/2020 10:02:37 \n","\n","04/18/2020 10:02:37 \n","\n","04/18/2020 10:03:29 dev EM: 66.58467360454115 F1: 76.62281986482402\n","04/18/2020 10:03:29 dev EM: 66.58467360454115 F1: 76.62281986482402\n","04/18/2020 10:03:29 dev EM: 66.58467360454115 F1: 76.62281986482402\n","04/18/2020 10:03:29 dawn_entry: 10\t0.7662281986482402\t1.559780513888889\n","04/18/2020 10:03:29 dawn_entry: 10\t0.7662281986482402\t1.559780513888889\n","04/18/2020 10:03:29 dawn_entry: 10\t0.7662281986482402\t1.559780513888889\n","04/18/2020 10:03:29 Epoch 11\n","04/18/2020 10:03:29 Epoch 11\n","04/18/2020 10:03:29 Epoch 11\n","04/18/2020 10:11:35 \n","\n","04/18/2020 10:11:35 \n","\n","04/18/2020 10:11:35 \n","\n","04/18/2020 10:12:27 dev EM: 67.41721854304636 F1: 76.94844253869847\n","04/18/2020 10:12:27 dev EM: 67.41721854304636 F1: 76.94844253869847\n","04/18/2020 10:12:27 dev EM: 67.41721854304636 F1: 76.94844253869847\n","04/18/2020 10:12:27 dawn_entry: 11\t0.7694844253869847\t1.7091429908333333\n","04/18/2020 10:12:27 dawn_entry: 11\t0.7694844253869847\t1.7091429908333333\n","04/18/2020 10:12:27 dawn_entry: 11\t0.7694844253869847\t1.7091429908333333\n","04/18/2020 10:12:27 Epoch 12\n","04/18/2020 10:12:27 Epoch 12\n","04/18/2020 10:12:27 Epoch 12\n","04/18/2020 10:20:34 \n","\n","04/18/2020 10:20:34 \n","\n","04/18/2020 10:20:34 \n","\n","04/18/2020 10:21:27 dev EM: 66.81173131504258 F1: 76.87232657159026\n","04/18/2020 10:21:27 dev EM: 66.81173131504258 F1: 76.87232657159026\n","04/18/2020 10:21:27 dev EM: 66.81173131504258 F1: 76.87232657159026\n","04/18/2020 10:21:27 dawn_entry: 12\t0.7687232657159027\t1.859223758611111\n","04/18/2020 10:21:27 dawn_entry: 12\t0.7687232657159027\t1.859223758611111\n","04/18/2020 10:21:27 dawn_entry: 12\t0.7687232657159027\t1.859223758611111\n","04/18/2020 10:21:27 Epoch 13\n","04/18/2020 10:21:27 Epoch 13\n","04/18/2020 10:21:27 Epoch 13\n","04/18/2020 10:29:39 \n","\n","04/18/2020 10:29:39 \n","\n","04/18/2020 10:29:39 \n","\n","04/18/2020 10:30:31 dev EM: 67.05771050141911 F1: 76.75828704178231\n","04/18/2020 10:30:31 dev EM: 67.05771050141911 F1: 76.75828704178231\n","04/18/2020 10:30:31 dev EM: 67.05771050141911 F1: 76.75828704178231\n","04/18/2020 10:30:31 dawn_entry: 13\t0.7675828704178231\t2.0103490822222225\n","04/18/2020 10:30:31 dawn_entry: 13\t0.7675828704178231\t2.0103490822222225\n","04/18/2020 10:30:31 dawn_entry: 13\t0.7675828704178231\t2.0103490822222225\n","04/18/2020 10:30:31 Epoch 14\n","04/18/2020 10:30:31 Epoch 14\n","04/18/2020 10:30:31 Epoch 14\n","04/18/2020 10:38:41 \n","\n","04/18/2020 10:38:41 \n","\n","04/18/2020 10:38:41 \n","\n","04/18/2020 10:39:33 dev EM: 67.4077578051088 F1: 77.2414175094658\n","04/18/2020 10:39:33 dev EM: 67.4077578051088 F1: 77.2414175094658\n","04/18/2020 10:39:33 dev EM: 67.4077578051088 F1: 77.2414175094658\n","04/18/2020 10:39:33 dawn_entry: 14\t0.772414175094658\t2.1608088083333334\n","04/18/2020 10:39:33 dawn_entry: 14\t0.772414175094658\t2.1608088083333334\n","04/18/2020 10:39:33 dawn_entry: 14\t0.772414175094658\t2.1608088083333334\n","04/18/2020 10:39:33 Epoch 15\n","04/18/2020 10:39:33 Epoch 15\n","04/18/2020 10:39:33 Epoch 15\n","04/18/2020 10:47:45 \n","\n","04/18/2020 10:47:45 \n","\n","04/18/2020 10:47:45 \n","\n","04/18/2020 10:48:38 dev EM: 67.64427625354777 F1: 77.29517478935472\n","04/18/2020 10:48:38 dev EM: 67.64427625354777 F1: 77.29517478935472\n","04/18/2020 10:48:38 dev EM: 67.64427625354777 F1: 77.29517478935472\n","04/18/2020 10:48:38 dawn_entry: 15\t0.7729517478935471\t2.3122927080555553\n","04/18/2020 10:48:38 dawn_entry: 15\t0.7729517478935471\t2.3122927080555553\n","04/18/2020 10:48:38 dawn_entry: 15\t0.7729517478935471\t2.3122927080555553\n","04/18/2020 10:48:38 Epoch 16\n","04/18/2020 10:48:38 Epoch 16\n","04/18/2020 10:48:38 Epoch 16\n","04/18/2020 10:56:55 \n","\n","04/18/2020 10:56:55 \n","\n","04/18/2020 10:56:55 \n","\n","04/18/2020 10:57:48 dev EM: 67.58751182592242 F1: 77.13905058133612\n","04/18/2020 10:57:48 dev EM: 67.58751182592242 F1: 77.13905058133612\n","04/18/2020 10:57:48 dev EM: 67.58751182592242 F1: 77.13905058133612\n","04/18/2020 10:57:48 dawn_entry: 16\t0.7713905058133612\t2.4651594280555558\n","04/18/2020 10:57:48 dawn_entry: 16\t0.7713905058133612\t2.4651594280555558\n","04/18/2020 10:57:48 dawn_entry: 16\t0.7713905058133612\t2.4651594280555558\n","04/18/2020 10:57:48 Epoch 17\n","04/18/2020 10:57:48 Epoch 17\n","04/18/2020 10:57:48 Epoch 17\n","04/18/2020 11:06:04 \n","\n","04/18/2020 11:06:04 \n","\n","04/18/2020 11:06:04 \n","\n","04/18/2020 11:06:57 dev EM: 68.34437086092716 F1: 77.73880431957288\n","04/18/2020 11:06:57 dev EM: 68.34437086092716 F1: 77.73880431957288\n","04/18/2020 11:06:57 dev EM: 68.34437086092716 F1: 77.73880431957288\n","04/18/2020 11:06:57 dawn_entry: 17\t0.7773880431957287\t2.6174495663888893\n","04/18/2020 11:06:57 dawn_entry: 17\t0.7773880431957287\t2.6174495663888893\n","04/18/2020 11:06:57 dawn_entry: 17\t0.7773880431957287\t2.6174495663888893\n","04/18/2020 11:06:57 Epoch 18\n","04/18/2020 11:06:57 Epoch 18\n","04/18/2020 11:06:57 Epoch 18\n","04/18/2020 11:15:07 \n","\n","04/18/2020 11:15:07 \n","\n","04/18/2020 11:15:07 \n","\n","04/18/2020 11:15:59 dev EM: 68.11731315042573 F1: 77.56777278519445\n","04/18/2020 11:15:59 dev EM: 68.11731315042573 F1: 77.56777278519445\n","04/18/2020 11:15:59 dev EM: 68.11731315042573 F1: 77.56777278519445\n","04/18/2020 11:15:59 dawn_entry: 18\t0.7756777278519444\t2.7681538066666667\n","04/18/2020 11:15:59 dawn_entry: 18\t0.7756777278519444\t2.7681538066666667\n","04/18/2020 11:15:59 dawn_entry: 18\t0.7756777278519444\t2.7681538066666667\n","04/18/2020 11:15:59 Epoch 19\n","04/18/2020 11:15:59 Epoch 19\n","04/18/2020 11:15:59 Epoch 19\n","04/18/2020 11:24:07 \n","\n","04/18/2020 11:24:07 \n","\n","04/18/2020 11:24:07 \n","\n","04/18/2020 11:24:59 dev EM: 68.25922421948913 F1: 77.77234053144257\n","04/18/2020 11:24:59 dev EM: 68.25922421948913 F1: 77.77234053144257\n","04/18/2020 11:24:59 dev EM: 68.25922421948913 F1: 77.77234053144257\n","04/18/2020 11:24:59 dawn_entry: 19\t0.7777234053144256\t2.918221111111111\n","04/18/2020 11:24:59 dawn_entry: 19\t0.7777234053144256\t2.918221111111111\n","04/18/2020 11:24:59 dawn_entry: 19\t0.7777234053144256\t2.918221111111111\n","04/18/2020 11:24:59 Epoch 20\n","04/18/2020 11:24:59 Epoch 20\n","04/18/2020 11:24:59 Epoch 20\n","04/18/2020 11:33:05 \n","\n","04/18/2020 11:33:05 \n","\n","04/18/2020 11:33:05 \n","\n","04/18/2020 11:33:57 dev EM: 67.95648060548723 F1: 77.6719752230192\n","04/18/2020 11:33:57 dev EM: 67.95648060548723 F1: 77.6719752230192\n","04/18/2020 11:33:57 dev EM: 67.95648060548723 F1: 77.6719752230192\n","04/18/2020 11:33:57 dawn_entry: 20\t0.7767197522301921\t3.067627609444444\n","04/18/2020 11:33:57 dawn_entry: 20\t0.7767197522301921\t3.067627609444444\n","04/18/2020 11:33:57 dawn_entry: 20\t0.7767197522301921\t3.067627609444444\n","04/18/2020 11:33:57 Epoch 21\n","04/18/2020 11:33:57 Epoch 21\n","04/18/2020 11:33:57 Epoch 21\n","Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]}]}